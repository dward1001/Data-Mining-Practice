{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 01 loss = 1.329088\n",
      "Epoch: 02 loss = 0.458111\n",
      "Epoch: 03 loss = 0.379328\n",
      "Epoch: 04 loss = 0.322503\n",
      "Epoch: 05 loss = 0.219824\n",
      "Epoch: 06 loss = 0.194274\n",
      "Epoch: 07 loss = 0.173604\n",
      "Epoch: 08 loss = 0.157446\n",
      "Epoch: 09 loss = 0.140268\n",
      "Epoch: 10 loss = 0.131198\n",
      "Epoch: 11 loss = 0.125750\n",
      "Epoch: 12 loss = 0.117288\n",
      "Epoch: 13 loss = 0.107748\n",
      "Epoch: 14 loss = 0.100604\n",
      "Epoch: 15 loss = 0.099303\n",
      "Epoch: 16 loss = 0.091289\n",
      "Epoch: 17 loss = 0.088796\n",
      "Epoch: 18 loss = 0.087121\n",
      "Epoch: 19 loss = 0.080355\n",
      "Epoch: 20 loss = 0.078453\n",
      "Test accuracy: 0.9594\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#parameters\n",
    "learning_rate = 0.005\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "SUMMARY_DIR = './mnist'\n",
    "\n",
    "#load mnist dataset\n",
    "MNIST = input_data.read_data_sets(\"./MNIST_data\",one_hot=True)\n",
    "\n",
    "with tf.name_scope('input') as scope:\n",
    "    X = tf.placeholder(tf.float32, [None, 784], name='image')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name = 'label')\n",
    "    \n",
    "with tf.variable_scope('layer1') as scope:\n",
    "    W1 = tf.get_variable(\"W\", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([512]))\n",
    "    L1 = tf.nn.softmax(tf.add(tf.matmul(X,W1),b1))\n",
    "    \n",
    "with tf.variable_scope('layer2') as scope:\n",
    "    W2 = tf.get_variable(\"W\", shape=[512, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([20]))\n",
    "    L2 = tf.nn.softmax(tf.add(tf.matmul(L1,W2),b2))\n",
    "\n",
    "with tf.variable_scope('layer3') as scope:\n",
    "    W3 = tf.get_variable(\"W\", shape=[20, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([10]))\n",
    "    y_ = tf.add(tf.matmul(L2, W3), b3)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "#merge all summaries\n",
    "summary = tf.summary.merge_all()\n",
    "\n",
    "def get_train_batch(batch_size):\n",
    "    if not hasattr(get_train_batch, \"index\"):\n",
    "        get_train_batch._images = MNIST.train.images\n",
    "        get_train_batch._labels = MNIST.train.labels\n",
    "        get_train_batch.size = MNIST.train.images.shape[0]\n",
    "        get_train_batch.index = 0\n",
    "        \n",
    "        random_st = numpy.random.get_state()\n",
    "        numpy.random.shuffle(get_train_batch._images)\n",
    "        numpy.random.set_state(random_st)\n",
    "        numpy.random.shuffle(get_train_batch._labels)\n",
    "        \n",
    "    if get_train_batch.index + 128 >= get_train_batch.size:\n",
    "        train_batch = (get_train_batch._images[get_train_batch.index:get_train_batch.size,],\n",
    "                       get_train_batch._labels[get_train_batch.index:get_train_batch.size,])\n",
    "        get_train_batch.index = 0\n",
    "        \n",
    "        random_st = numpy.random.get_state()\n",
    "        numpy.random.shuffle(get_train_batch._images)\n",
    "        numpy.random.set_state(random_st)\n",
    "        numpy.random.shuffle(get_train_batch._labels)\n",
    "    else:\n",
    "        start = get_train_batch.index\n",
    "        get_train_batch.index += 128\n",
    "        end = get_train_batch.index\n",
    "        train_batch = (get_train_batch._images[start:end], get_train_batch._labels[start:end])\n",
    "    return train_batch\n",
    "\n",
    "global_step = 0\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#with tf.Session(config = config) as see:\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(SUMMARY_DIR, sess.graph)\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(MNIST.train.num_examples / batch_size)\n",
    "        avg_loss = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            #batch_xs, batch_ys = MNIST.train.next_batch(batch_size)\n",
    "            batch_xs, batch_ys = get_train_batch(batch_size)\n",
    "            feed_dict = {X: batch_xs, y: batch_ys}\n",
    "            s, l, _ = sess.run([summary, loss, optimizer], feed_dict=feed_dict)\n",
    "            writer.add_summary(s, global_step=global_step)\n",
    "            global_step += 1\n",
    "            avg_loss += l\n",
    "        print('Epoch:', '%02d' % (epoch + 1), 'loss =', '{:.6f}'.format(avg_loss / total_batch))\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    acc = sess.run(accuracy, feed_dict= {X: MNIST.test.images, y: MNIST.test.labels})\n",
    "    print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
